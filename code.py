# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lutFCpGJBazFSnUGH25qT8d9iytz_44Q
"""

! git clone https://github.com/deepklarity/fastai-bert-finetuning.git fastai_bert_finetuning
! mv fastai_bert_finetuning/* .
! rm -fr fastai_bert_finetuning

! pip install -r requirements.txt

import csv
import pandas as pd
from pathlib import Path
import matplotlib.cm as cm
from fastai import *
from fastai.text import *
from fastai.callbacks import *
from fastai.metrics import *
# from fastai import xl
import utils, bert_fastai, bert_helper

TASK='MRPC'
DATA_ROOT = Path(".")
label_col = "Quality"
text_cols = ["#1 String", "#2 String"]
! python download_glue_data.py --data_dir='glue_data' --tasks=$TASK --test_labels=True

train_df = pd.read_csv(DATA_ROOT / "glue_data" / "MRPC" / "train.tsv", sep = '\t', quoting=csv.QUOTE_NONE)
# train_df.head()

test_df = pd.read_csv(DATA_ROOT / "glue_data" / "MRPC" / "test.tsv", sep = '\t', quoting=csv.QUOTE_NONE)
# test_df.head()

config = utils.Config(
    bert_model_name="bert-base-uncased",
    num_labels=2, # 0 or 1
    max_lr=2e-5,
    epochs=3,
    batch_size=32,
    max_seq_len=128
)

fastai_tokenizer = bert_fastai.FastAITokenizer(model_name=config.bert_model_name, max_seq_len=config.max_seq_len)

databunch = TextDataBunch.from_df(".", train_df=train_df, valid_df=test_df,
                  tokenizer=fastai_tokenizer.bert_tokenizer(),
                  vocab=fastai_tokenizer.fastai_bert_vocab(),
                  include_bos=False,
                  include_eos=False,
                  text_cols=text_cols,
                  label_cols=label_col,
                  bs=config.batch_size,
                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),
             )

lr = 1e-5
learner.fit_one_cycle(1, 
                      max_lr=slice(lr*0.95**num_groups, lr), 
                      moms=(0.8, 0.9))

# from pytorch_pretrained


from pytorch_pretrained_bert.modeling import BertConfig, BertForSequenceClassification


bert_model = BertForSequenceClassification.from_pretrained(
    config.bert_model_name, num_labels=config.num_labels)

learner = bert_fastai.BertLearner(databunch,
                                  bert_model,
                                  metrics=[accuracy])

learner.callbacks.append(ShowGraph(learner))

preds, pred_values, true_labels = learner.get_predictions()
learner.print_metrics(preds, pred_values, true_labels)

txt_ci = TextClassificationInterpretation.from_learner(learner)

learner.fit_one_cycle(config.epochs, max_lr=config.max_lr)

preds, pred_values, true_labels = learner.get_predictions()
learner.print_metrics(preds, pred_values, true_labels)